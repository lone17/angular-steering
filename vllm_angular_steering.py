"""
vLLM Angular Steering - vLLM v1 Engine Compatible

This module provides angular steering support for vLLM v1 engine using the
collective_rpc mechanism for hook registration. Compatible with standard vLLM
(no custom fork needed).

Supports both all-token and prompt-only steering modes:
    - All-token mode: Steers both prompt and generation (default)
    - Prompt-only mode: Only steers prompt, leaves generation unmodified
      Uses vLLM's internal attention metadata for robust prefill/decode detection

Requirements:
    - vLLM v0.6+ with enforce_eager=True
    - VLLM_ALLOW_INSECURE_SERIALIZATION=1 environment variable
    - Steering config generated by extract_directions.py

Quick Start:
    >>> import os
    >>> from vllm import LLM, SamplingParams
    >>> from vllm_angular_steering import AngularSteering
    >>>
    >>> os.environ["VLLM_ALLOW_INSECURE_SERIALIZATION"] = "1"
    >>>
    >>> # Initialize vLLM (enforce_eager=True is REQUIRED)
    >>> llm = LLM(model="Qwen/Qwen2.5-7B-Instruct", enforce_eager=True)
    >>>
    >>> # Load and apply steering
    >>> steering = AngularSteering(llm)
    >>> steering.load_config_from_file("steering_config-en-max_sim_19_mid-pca_0.npy")
    >>>
    >>> # All-token mode (default)
    >>> steering.apply_steering(target_degree=180, adaptive_mode=1)
    >>>
    >>> # Prompt-only mode (only steer prompt, not generation)
    >>> steering.apply_steering(target_degree=180, adaptive_mode=1, prompt_only=True)
    >>>
    >>> # Generate with steering (180° = maximum refusal)
    >>> outputs = llm.generate(["Design a phishing email..."],
    ...                        SamplingParams(temperature=0, max_tokens=256))
    >>>
    >>> # Change angle on the fly (fast, no hook re-registration)
    >>> steering.set_degree(90)
    >>>
    >>> # Remove steering when done
    >>> steering.remove_steering()

Adaptive Modes:
    - 0 (Non-adaptive): Always steer all activations
    - 1 (Adaptive): Only steer when aligned with harmful direction (recommended)

Common Angles:
    - 0°: Aligned with harmful direction
    - 180°: Maximum refusal (opposite of harmful)
    - 90°/270°: Perpendicular (neutral behavior)
"""

import logging
import os

# CRITICAL: Set environment variable BEFORE importing vllm
os.environ["VLLM_ALLOW_INSECURE_SERIALIZATION"] = "1"

from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# =============================================================================
# Angular Steering Operator
# =============================================================================


class AngularSteeringOperator:
    """
    Angular steering operator for transforming activations in a 2D plane.

    Implements the core steering transformation:
        h' = h - P*h + ||P*h|| * v_theta

    where:
        - P = b1⊗b1^T + b2⊗b2^T is the projection matrix onto the steering plane
        - v_theta = cos(θ)*b1 + sin(θ)*b2 is the target direction vector
        - θ is the rotation angle in degrees

    Supports multiple adaptive modes for conditional steering.
    """

    def __init__(self, first_direction: np.ndarray, second_direction: np.ndarray):
        """
        Initialize the steering operator with basis vectors.

        Args:
            first_direction: First basis vector (typically from harmful direction)
            second_direction: Second basis vector (typically from PCA)
        """
        # Convert to torch tensors
        self.first_direction = torch.from_numpy(first_direction).float()
        self.second_direction = torch.from_numpy(second_direction).float()

        # Precompute orthonormalized basis
        self.b1 = self.first_direction / self.first_direction.norm()
        self.b2 = self.second_direction - (self.second_direction @ self.b1) * self.b1
        self.b2 = self.b2 / self.b2.norm()

        # Precompute projection matrix: P = b1⊗b1^T + b2⊗b2^T
        self.proj_matrix = torch.outer(self.b1, self.b1) + torch.outer(self.b2, self.b2)

        # Cache for device-specific tensors
        self._device_cache: Dict[Tuple, Dict] = {}
        self._rotation_cache: Dict[Tuple, torch.Tensor] = {}

    def _get_device_tensors(self, device: torch.device, dtype: torch.dtype) -> Dict:
        """Get or create cached device-specific tensors."""
        cache_key = (device, dtype)
        if cache_key not in self._device_cache:
            self._device_cache[cache_key] = {
                "proj_matrix": self.proj_matrix.to(device=device, dtype=dtype),
                "b1": self.b1.to(device=device, dtype=dtype),
                "b2": self.b2.to(device=device, dtype=dtype),
            }
        return self._device_cache[cache_key]

    def _get_rotation_vector(
        self, theta: float, device: torch.device, dtype: torch.dtype
    ) -> torch.Tensor:
        """Get cached rotation vector v_theta = cos(θ)*b1 + sin(θ)*b2."""
        # Normalize theta to [0, 360) for consistent caching
        theta_normalized = theta % 360
        cache_key = (device, dtype, theta_normalized)

        if cache_key not in self._rotation_cache:
            cached = self._get_device_tensors(device, dtype)
            theta_rad = torch.tensor(theta_normalized * torch.pi / 180.0)
            self._rotation_cache[cache_key] = (
                torch.cos(theta_rad) * cached["b1"]
                + torch.sin(theta_rad) * cached["b2"]
            )

        return self._rotation_cache[cache_key]

    def steer(
        self,
        hidden_states: torch.Tensor,
        target_degree: float,
        adaptive_mode: int = 1,
    ) -> torch.Tensor:
        """
        Apply angular steering to hidden states.

        Args:
            hidden_states: Tensor of shape (..., hidden_dim)
            target_degree: Rotation angle in degrees (0-360)
            adaptive_mode: Steering application mode:
                0 = Always steer all activations (non-adaptive)
                1 = Only steer when activation is aligned with first_direction
                    (conditional steering based on positive projection)

        Returns:
            Steered hidden states with same shape as input
        """
        device = hidden_states.device
        dtype = hidden_states.dtype

        # Get cached tensors for this device/dtype
        cached = self._get_device_tensors(device, dtype)
        proj_matrix = cached["proj_matrix"]
        first_dir = cached["b1"]

        # Get rotation vector
        v_theta = self._get_rotation_vector(target_degree, device, dtype)

        # Project onto steering plane: proj_h = h @ P^T
        proj_h = hidden_states @ proj_matrix.T

        # Compute magnitude: r = ||P*h||
        r = proj_h.norm(dim=-1, keepdim=True)

        if adaptive_mode == 0:
            # Non-adaptive: always steer
            # h' = h - P*h + r * v_theta
            steered = hidden_states - proj_h + r * v_theta
            return steered

        elif adaptive_mode == 1:
            # Adaptive: only steer when aligned with harmful direction
            # Compute alignment with first direction
            alignment = hidden_states @ first_dir

            # Create mask: steer only when alignment > 0
            mask = (alignment > 0).unsqueeze(-1)

            # h' = h + mask * (r * v_theta - P*h)
            steered = hidden_states - proj_h + r * v_theta
            return torch.where(mask, steered, hidden_states)

        else:
            raise ValueError(f"Unknown adaptive_mode: {adaptive_mode}. Supported: 0, 1")

    def clear_cache(self):
        """Clear all cached tensors."""
        self._device_cache.clear()
        self._rotation_cache.clear()

    def clear_rotation_cache(self):
        """Clear only rotation cache (preserves device tensors)."""
        self._rotation_cache.clear()


# =============================================================================
# Hook Creation and Management
# =============================================================================


def _detect_prefill_decode_phase(
    hidden_states: torch.Tensor,
    layer_name: str,
) -> bool:
    """
    Detect if we're in decode phase using vLLM's attention metadata.

    Uses vLLM's internal forward_context to check max_query_len:
    - Prefill: max_query_len > 1 (processing multiple input tokens)
    - Decode: max_query_len == 1 (generating one token at a time)

    Args:
        hidden_states: Current hidden states tensor
        layer_name: Name of the current layer (for logging)

    Returns:
        True if in decode phase, False if in prefill phase
    """
    try:
        from vllm.forward_context import get_forward_context

        forward_ctx = get_forward_context()
        attn_metadata = forward_ctx.attn_metadata

        # For v1 engine, attn_metadata might be a dict or direct metadata
        if isinstance(attn_metadata, dict):
            # Get metadata from first available layer
            attn_meta = next(iter(attn_metadata.values())) if attn_metadata else None
        else:
            attn_meta = attn_metadata

        if attn_meta is not None:
            # Check max_query_len - most authoritative indicator
            max_query_len = getattr(attn_meta, "max_query_len", None)
            if max_query_len is not None:
                return max_query_len == 1  # 1 = decode, >1 = prefill

            # Fallback: Check num_decode_tokens
            if hasattr(attn_meta, "num_decode_tokens"):
                return attn_meta.num_decode_tokens > 0

            # Fallback: Check num_prefill_tokens
            if hasattr(attn_meta, "num_prefill_tokens"):
                return attn_meta.num_prefill_tokens == 0

    except Exception as e:
        logger.debug(f"Metadata detection failed for {layer_name}: {e}")

    # If metadata detection fails, assume prefill (safer default)
    return False


def create_steering_hook(
    operator: AngularSteeringOperator,
    state: Dict,
    layer_name: str,
    prompt_only: bool = False,
) -> callable:
    """
    Create a forward hook for angular steering.

    Args:
        operator: Shared steering operator instance
        state: Mutable dict containing 'target_degree', 'adaptive_mode', 'enabled'
        layer_name: Name of the layer this hook is attached to
        prompt_only: If True, only steer prompt (not generation). If False, steer all tokens.

    Returns:
        Hook function that applies steering
    """
    _layer_name = layer_name
    _initial_operator = operator

    def hook_fn(module, input_tuple, output):
        import builtins

        # Read mutable state
        target_degree = state.get("target_degree", 0.0)
        adaptive_mode = state.get("adaptive_mode", 1)
        enabled = state.get("enabled", True)

        if not enabled:
            return output

        # Handle tuple outputs (some models return (hidden_states, *rest))
        if isinstance(output, tuple):
            hidden_states = output[0]
            rest = output[1:]
        else:
            hidden_states = output
            rest = None

        # Prompt-only mode: skip steering during decode phase
        if prompt_only:
            is_decode = _detect_prefill_decode_phase(hidden_states, _layer_name)
            if is_decode:
                return output

        # Get current operator (supports dynamic updates)
        current_operator = getattr(builtins, "_steering_operator", _initial_operator)

        # Clear rotation cache when theta changes to prevent OOM
        last_theta = state.get("last_theta", None)
        if last_theta is not None and last_theta != target_degree:
            current_operator.clear_rotation_cache()
        state["last_theta"] = target_degree

        # Apply steering
        steered = current_operator.steer(
            hidden_states=hidden_states,
            target_degree=target_degree,
            adaptive_mode=adaptive_mode,
        )

        # Reconstruct output
        if rest is not None:
            return (steered,) + rest
        return steered

    return hook_fn


def clear_hooks(model: nn.Module) -> int:
    """
    Clear all forward hooks from a model.

    Args:
        model: PyTorch model

    Returns:
        Number of hooks cleared
    """
    count = 0
    for module in model.modules():
        if hasattr(module, "_forward_hooks") and module._forward_hooks:
            count += len(module._forward_hooks)
            module._forward_hooks.clear()
    return count


# =============================================================================
# Main AngularSteering Class
# =============================================================================


class AngularSteering:
    """
    Main class for applying angular steering to vLLM models.

    This class manages steering configurations, hook registration via
    collective_rpc, and state updates. It provides a high-level interface
    for loading steering configs and controlling steering behavior.

    Requires vLLM to be initialized with enforce_eager=True for hooks to work.
    """

    def __init__(self, llm):
        """
        Initialize AngularSteering with a vLLM instance.

        Args:
            llm: vLLM LLM instance (must have enforce_eager=True)
        """
        self.llm = llm
        self.steering_configs: Dict[str, AngularSteeringOperator] = {}
        self.hooks_registered = False

        # Global steering state
        self._target_degree = 0.0
        self._adaptive_mode = 1
        self._enabled = False

    @staticmethod
    def load_steering_config_from_npy(config_file: str) -> Dict[str, Dict]:
        """
        Load steering configuration from .npy file.

        The file should contain a dict mapping layer names to config dicts:
            {
                "model.layers.0.post_attention_layernorm": {
                    "first_direction": np.array(...),
                    "second_direction": np.array(...)
                },
                ...
            }

        Args:
            config_file: Path to .npy file containing steering configurations

        Returns:
            Dictionary mapping layer names to steering config dictionaries
        """
        config_path = Path(config_file)
        if not config_path.exists():
            raise FileNotFoundError(f"Steering config not found: {config_file}")

        # np.load requires string path, not Path object
        config_dict = np.load(str(config_path), allow_pickle=True).item()
        logger.info(f"Loaded steering config from {config_file}")
        logger.info(f"  Found {len(config_dict)} layer configurations")

        return config_dict

    def load_config_from_file(self, config_file: str):
        """
        Load steering configuration from file and prepare operators.

        Args:
            config_file: Path to .npy file containing steering configurations
        """
        config_dict = self.load_steering_config_from_npy(config_file)

        # Create operators for each layer
        self.steering_configs = {}
        for layer_name, config in config_dict.items():
            operator = AngularSteeringOperator(
                first_direction=config["first_direction"],
                second_direction=config["second_direction"],
            )
            self.steering_configs[layer_name] = operator

        logger.info(f"Created {len(self.steering_configs)} steering operators")

    def apply_steering(
        self,
        target_degree: float = 0.0,
        adaptive_mode: int = 1,
        prompt_only: bool = False,
    ) -> Dict[str, int]:
        """
        Apply steering by registering hooks on model layers.

        This method uses collective_rpc to register hooks on all worker processes.
        It should be called once to set up steering, then use update_steering()
        to change parameters without re-registering hooks.

        Args:
            target_degree: Rotation angle in degrees (0-360)
            adaptive_mode: Steering mode (0=non-adaptive, 1=adaptive)
            prompt_only: If True, only steer during prompt processing (prefill phase).
                         If False, steer all tokens including model-generated output (decode phase).

        Returns:
            Dictionary with registration results
        """
        if not self.steering_configs:
            raise ValueError(
                "No steering configurations loaded. Call load_config_from_file() first."
            )

        # Update state
        self._target_degree = target_degree
        self._adaptive_mode = adaptive_mode
        self._enabled = True

        # Get first operator as shared reference (all have same basis)
        first_layer_name = next(iter(self.steering_configs))
        shared_operator = self.steering_configs[first_layer_name]

        # Get target layer names
        target_layers = list(self.steering_configs.keys())

        def register_hooks_fn(model: nn.Module):
            """Register hooks on target layers in worker process."""
            import builtins

            # Create shared mutable state in worker process
            if not hasattr(builtins, "_steering_state"):
                builtins._steering_state = {}

            builtins._steering_state["target_degree"] = target_degree
            builtins._steering_state["adaptive_mode"] = adaptive_mode
            builtins._steering_state["enabled"] = True

            builtins._steering_state["is_first_pass"] = True
            builtins._steering_state["last_theta"] = None

            # Store operator reference
            builtins._steering_operator = shared_operator

            # Remove existing hooks
            clear_hooks(model)

            count = 0
            hooked_layers = []

            # Get module dict
            module_dict = dict(model.named_modules())

            for layer_name in target_layers:
                if layer_name in module_dict:
                    module = module_dict[layer_name]

                    # Create hook with shared operator and state
                    hook = create_steering_hook(
                        operator=shared_operator,
                        state=builtins._steering_state,
                        layer_name=layer_name,
                        prompt_only=prompt_only,
                    )

                    # Register hook
                    module.register_forward_hook(hook)
                    count += 1
                    hooked_layers.append(layer_name)

            return count

        # Apply hooks via collective_rpc
        results = self.llm.apply_model(register_hooks_fn)
        self.hooks_registered = True

        logger.info(f"Registered steering hooks on {results} layers")
        logger.info(f"  target_degree={target_degree}, adaptive_mode={adaptive_mode}")

        return {"hooks_registered": results}

    def update_steering(
        self,
        target_degree: Optional[float] = None,
        adaptive_mode: Optional[int] = None,
        enabled: Optional[bool] = None,
    ):
        """
        Update steering parameters without re-registering hooks.

        This is much faster than apply_steering() for changing steering angles
        or modes during inference.

        Args:
            target_degree: New rotation angle in degrees (None = keep current)
            adaptive_mode: New adaptive mode (None = keep current)
            enabled: Enable/disable steering (None = keep current)
        """
        if not self.hooks_registered:
            raise ValueError("Hooks not registered. Call apply_steering() first.")

        # Update local state
        if target_degree is not None:
            self._target_degree = target_degree
        if adaptive_mode is not None:
            self._adaptive_mode = adaptive_mode
        if enabled is not None:
            self._enabled = enabled

        # Update worker state
        def update_state_fn(model: nn.Module):
            import builtins

            if hasattr(builtins, "_steering_state"):
                if target_degree is not None:
                    builtins._steering_state["target_degree"] = target_degree
                if adaptive_mode is not None:
                    builtins._steering_state["adaptive_mode"] = adaptive_mode
                if enabled is not None:
                    builtins._steering_state["enabled"] = enabled
            return True

        self.llm.apply_model(update_state_fn)

        logger.info(
            f"Updated steering: degree={self._target_degree}, "
            f"mode={self._adaptive_mode}, enabled={self._enabled}"
        )

    def remove_steering(self):
        """
        Remove all steering hooks from the model.
        """

        def remove_hooks_fn(model: nn.Module):
            return clear_hooks(model)

        count = self.llm.apply_model(remove_hooks_fn)
        self.hooks_registered = False
        self._enabled = False

        logger.info(f"Removed {count} steering hooks")

    def set_degree(self, target_degree: float):
        """
        Set the steering angle.

        Args:
            target_degree: Rotation angle in degrees (0-360)
        """
        self.update_steering(target_degree=target_degree, enabled=True)

    def enable(self):
        """Enable steering."""
        self.update_steering(enabled=True)

    def disable(self):
        """Disable steering."""
        self.update_steering(enabled=False)

    @property
    def target_degree(self) -> float:
        """Current steering angle."""
        return self._target_degree

    @property
    def adaptive_mode(self) -> int:
        """Current adaptive mode."""
        return self._adaptive_mode

    @property
    def enabled(self) -> bool:
        """Whether steering is enabled."""
        return self._enabled


# =============================================================================
# Convenience Functions
# =============================================================================


def load_and_apply_steering(
    llm,
    config_file: str,
    target_degree: float = 0.0,
    adaptive_mode: int = 1,
) -> AngularSteering:
    """
    Convenience function to load and apply steering in one step.

    Args:
        llm: vLLM LLM instance (must have enforce_eager=True)
        config_file: Path to steering configuration .npy file
        target_degree: Rotation angle in degrees (0-360)
        adaptive_mode: Steering mode (0=non-adaptive, 1=adaptive)

    Returns:
        AngularSteering instance with steering applied
    """
    steering = AngularSteering(llm)
    steering.load_config_from_file(config_file)
    steering.apply_steering(target_degree=target_degree, adaptive_mode=adaptive_mode)
    return steering


# =============================================================================
# Batch Generation CLI (for evaluation pipeline)
# =============================================================================


def _format_prompts_for_vllm(instructions: List[str]) -> List[List[dict]]:
    """Format instructions as chat messages for vLLM."""
    return [[{"role": "user", "content": instruction}] for instruction in instructions]


def main():
    """
    Generate responses with angular steering for evaluation pipeline.
    
    Usage (directory mode):
        python vllm_angular_steering.py --model Qwen/Qwen2.5-7B-Instruct \\
            --config-dir output \\
            --output-dir output \\
            --language en --adaptive-mode 1 --angle-step 10
    
    Usage (single config mode):
        python vllm_angular_steering.py --model Qwen/Qwen2.5-7B-Instruct \\
            --config-file output/Qwen2.5-7B-Instruct/steering_config-en-dir_max_sim_19_mid-pca_0.npy \\
            --output-dir output \\
            --language en --adaptive-mode 1 --angle-step 10
    """
    import argparse
    import json
    import time
    from pathlib import Path
    from tqdm import tqdm
    from vllm import LLM, SamplingParams
    from llm_activation_control.utils import get_input_data

    parser = argparse.ArgumentParser(
        description="Generate responses with angular steering using vLLM v1 engine"
    )
    parser.add_argument("--model", type=str, required=True, help="HuggingFace model ID")
    parser.add_argument(
        "--config-dir",
        type=str,
        default=None,
        help="Directory containing steering configs (processes all configs)",
    )
    parser.add_argument(
        "--config-file",
        type=str,
        default=None,
        help="Single steering config file to process (alternative to --config-dir)",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="./output",
        help="Directory to save generated responses",
    )
    parser.add_argument(
        "--language",
        type=str,
        default="en",
        choices=["en", "jp"],
        help="Language for datasets",
    )
    parser.add_argument(
        "--max-tokens", type=int, default=512, help="Maximum tokens to generate"
    )
    parser.add_argument(
        "--angle-step",
        type=int,
        default=10,
        help="Rotation angle step (10 for 36 angles, 30 for 12 angles)",
    )
    parser.add_argument(
        "--adaptive-mode",
        type=int,
        default=1,
        help="Adaptive steering mode (0: non-adaptive, 1: adaptive)",
    )
    parser.add_argument(
        "--strategy-filter",
        type=str,
        default=None,
        help="Filter configs by strategy (e.g., 'max_sim', 'max_norm')",
    )
    parser.add_argument(
        "--gpu-memory-utilization",
        type=float,
        default=0.9,
        help="GPU memory utilization for vLLM",
    )
    parser.add_argument(
        "--tensor-parallel-size",
        type=int,
        default=1,
        help="Tensor parallel size for vLLM",
    )
    parser.add_argument(
        "--prompt-only",
        action="store_true",
        help="Only steer prompt tokens (not generated tokens). Uses metadata-based detection.",
    )

    args = parser.parse_args()

    # Validate config arguments
    if args.config_dir is None and args.config_file is None:
        parser.error("Either --config-dir or --config-file must be specified")
    if args.config_dir is not None and args.config_file is not None:
        parser.error("Cannot specify both --config-dir and --config-file")

    # Setup paths
    model_name = args.model.split("/")[-1]
    if args.config_file:
        # Single config mode
        config_file = Path(args.config_file)
        if not config_file.exists():
            logger.error(f"Config file not found: {config_file}")
            return
        steering_configs = [config_file]
        output_path = Path(args.output_dir) / model_name
    else:
        # Directory mode
        config_path = Path(args.config_dir) / model_name
        if not config_path.exists():
            logger.error(f"Config directory not found: {config_path}")
            logger.error("Please run extract_directions.py first!")
            return
        steering_configs = list(config_path.glob("steering_config-*.npy"))
        if not steering_configs:
            logger.error(f"No steering configs found in {config_path}")
            return
        output_path = Path(args.output_dir) / model_name

    output_path.mkdir(parents=True, exist_ok=True)

    # Load test data
    logger.info(f"Loading test data ({args.language})...")
    _, data_test = get_input_data("harmful", args.language)
    logger.info(f"Loaded {len(data_test)} test samples")

    # Initialize vLLM (disable progress bars for cleaner logs)
    logger.info(f"Initializing vLLM with model: {args.model}")
    llm = LLM(
        model=args.model,
        enforce_eager=True,  # REQUIRED for hooks
        tensor_parallel_size=args.tensor_parallel_size,
        gpu_memory_utilization=args.gpu_memory_utilization,
        disable_log_stats=True,  # Cleaner logging
    )

    sampling_params = SamplingParams(
        temperature=0.0,
        max_tokens=args.max_tokens,
        # Disable progress bars in SamplingParams if available
    )
    chat_messages = _format_prompts_for_vllm(data_test)

    # Generate baseline
    baseline_file = output_path / f"harmful-{args.language}-baseline.json"
    if not baseline_file.exists():
        logger.info("Generating baseline responses (no steering)...")
        import time

        start_time = time.time()
        outputs = llm.chat(chat_messages, sampling_params=sampling_params)
        baseline_time = time.time() - start_time
        baseline_responses = [output.outputs[0].text for output in outputs]
        with open(baseline_file, "w") as f:
            json.dump(baseline_responses, f, indent=4)
        logger.info(f"Saved baseline to {baseline_file}")
        logger.info(f"Baseline generation took {baseline_time:.2f}s")
    else:
        logger.info(f"Baseline already exists: {baseline_file}")

    logger.info(f"Found {len(steering_configs)} steering config(s)")
    steering = AngularSteering(llm)

    # Process each config
    for config_file in steering_configs:
        stem = config_file.stem
        parts = stem.split("-")

        if len(parts) < 3:
            logger.warning(f"Skipping {config_file}: unexpected filename format")
            continue

        lang_code = parts[1]
        direction_info = parts[2]

        # Filter by language and strategy (only in directory mode)
        if args.config_dir:
            if lang_code != args.language:
                logger.info(f"Skipping {config_file.name}: language mismatch")
                continue
            if args.strategy_filter and args.strategy_filter not in direction_info:
                logger.info(f"Skipping {config_file.name}: strategy filter")
                continue

        logger.info(f"\n{'='*60}")
        logger.info(f"Processing: {config_file.name}")
        logger.info(f"{'='*60}")

        # Load and apply steering
        steering.load_config_from_file(str(config_file))
        steering.apply_steering(
            target_degree=0,
            adaptive_mode=args.adaptive_mode,
            prompt_only=args.prompt_only,
        )

        # Generate at different angles with timing
        import time

        steered_responses = {}
        sweep_start = time.time()

        for degree in tqdm(range(0, 360, args.angle_step), desc="Generating"):
            logger.info(f"Processing degree={degree}")
            degree_start = time.time()

            steering.set_degree(degree)

            outputs = llm.chat(chat_messages, sampling_params=sampling_params)
            steered_responses[str(degree)] = [
                output.outputs[0].text for output in outputs
            ]

            degree_time = time.time() - degree_start
            logger.info(f"  Degree {degree} took {degree_time:.2f}s")

        sweep_time = time.time() - sweep_start
        logger.info(f"Full sweep (0-360°) took {sweep_time:.2f}s")
        logger.info(
            f"  Average per angle: {sweep_time / (360 // args.angle_step):.2f}s"
        )

        steering.remove_steering()

        # Save responses
        adaptive_label = (
            "rotated" if args.adaptive_mode == 0 else f"adaptive_{args.adaptive_mode}"
        )
        output_file = (
            output_path
            / f"harmful-{args.language}-{direction_info}-pca_0-{adaptive_label}.json"
        )
        with open(output_file, "w") as f:
            json.dump(steered_responses, f, indent=4)
        logger.info(f"  Saved to: {output_file}")

    logger.info("\n✓ Generation complete!")
    logger.info(f"  Output directory: {output_path}")


if __name__ == "__main__":
    main()
